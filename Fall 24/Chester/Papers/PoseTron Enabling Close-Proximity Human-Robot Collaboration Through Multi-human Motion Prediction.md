Yasar, Iqbal | ACM\IEEE International Conference on Human-Robot Interaction 2024 | March 11th, 2024

**Link:** [PoseTron](https://dl.acm.org/doi/abs/10.1145/3610977.3635006)

**Conclusion:** 

Addresses the critical challenge of predicting human motion for safe and efficient human-robot collaboration (HRC). Mohammad Samin Yasar and his colleagues present a novel approach called PoseTron, a transformer-based encoder-decoder architecture that leverages a large-scale, multimodal dataset named INTERACT.

"INTERACT" this dataset is designed specifically for HRC research, featuring 3D skeleton data, RGB+D inputs from different angles, gaze tracking, and robot joint data collected from various collaborative scenarios, both human-human and human-robot. 

PoseTron introduces innovative mechanisms, such as a conditional attention mechanism in the encoder for better understanding team dynamics by effectively weighing motion information from multiple agents. The decoder uses a multimodal attention mechanism to integrate and predict motion across different sensory inputs.

PoseTronâ€™s potential to integrate motion prediction seamlessly with robotic perception, paving the way for safer and more fluid human-robot interactions.