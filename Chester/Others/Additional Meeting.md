
### October 2nd, 2024 - Donor Meeting

**October 1st, 2024 - Meeting**
- Talk about our Lab
	- Futuristic
- Talk about our Projects
	- Social Interaction
	- AI
	- Mental Health Care
	- How can help with people

**1st Draft**
- Our Lab
	- Through our research, we aim to enhance the emotional and physical support provided by robots, ultimately improving the quality of life and well-being for individuals. By bridging the gap between humans and technology, we strive to create meaningful, supportive interactions that bring us closer together, even when we’re physically apart.
- My Project (TurtleBot 2)
	- This project explores the interactions between humans and a group of mobile robots in a guided navigation context. Using TurtleBots upgraded with Raspberry Pis and running on ROS Noetic, we investigate how various aspects of multi-robot systems influence human reception and behavior. Our goal is to understand better how different configurations of robot behavior and environmental factors can optimize group interactions, enhance human comfort, and improve the effectiveness of robot-guided navigation in shared spaces
- Other Projects 
	- Affect-Sensing Wearable to Promote Social Interaction
		- The “Affect-Sensing Wearable” project aims to create a modular jacket that uses machine learning to interpret Bio signals and detect users emotional states. This technology allows external agents to provide emotional and physical support, enhancing social interaction through touch. By offering real-time feedback, the jacket addresses mental health needs, improves emotional communication, and promotes well-being, ultimately enhancing individuals’ quality of life
	- Baxter Robot
		- By enhancing the robot’s greeting and physical interactions, this project seeks to foster more positive first impressions between humans and robots. With the Baxter Robot on a mobile base and a compliant gripper with tactile sensors, we aim to create smoother, more intuitive engagement. These innovations will help robots interact more naturally, making users feel more at ease. Ultimately, this research will deepen our understanding of how initial robot encounters shape long-term human-robot relationships
	- Compliant Gripper
		- Enhances Baxter Robot’s interactions by integrating tactile sensors for more natural engagement. By improving greetings and physical touch, it fosters positive first impressions and user comfort, deepening our understanding of how initial encounters influence long-term human-robot relationships
	- Nao Robot
		- Integration of AI offers significant potential for enhancing mental health care and social interaction. By providing personalized support and engaging users, Nao helps reduce loneliness and foster connections. As it evolves, Nao can deliver accessible interventions, empowering individuals to improve emotional well-being and strengthen social ties, making it a valuable tool for nurturing connections and resilience

**2nd Draft**
- Lab
	- We develop empathetic robotics companion to address **mental health** concern and provide emotional support
	- Mental Health: Autism, Post-traumatic Stress Disorder (PTSD), Depression, Grief
		- Autism: A neurological and developmental disorder that affects how people interact with others, communicate, learn, and behave
		- PTSD: A disorder that develops in some people who have experienced a shocking, scary, or dangerous event
		- Depression: A constant feeling of sadness, which stops you doing your norma activities
		- Grief: A natural response to loss
- Projects
	- TurtleBot 2
		- We develop them to use as a swarm to potentially help navigate people when they arrive at our lab and we will investigate how multi-robot systems affect human reception and behavior
	- Nao Robot
		- It is a verbal robotic support. We want to develop an empathic friend that can be used as a daily tool when you can not go to a mental health professional immediately by **fine-tuning the best-performing LLM** 
			- LLM = Large Language Model
			- Fine-tune LLM: A supervised learning process where you use a dataset of labeled examples to update the weights of LLM and make the model improve its ability fir specific tasks 
	- Affect-Sensing Wearables
		- It uses machine learning to develop a bio signal system to express the wearer’s emotional state to promote social-physical human-human interaction to improve the emotional state
	- Compliant Gripper
		- Learning to comfort. It is a tactile robotic support. So, this will give the robots social-physical skills like hands for Baxter robot to comfort users when the y requesting human comfort is difficult or impossible
	- Baxter Robot
		- This is to enhance the robot’s greeting and physical interactions. We are seeking positive first impressions between humans and robots. As I mentioned before we use a compliant gripper with tactile in this project too

**Final Draft** 
- Lab
	- Human fusions institute is all about technology in the service of humanity. In the SaPHaRI Lab we develop empathetic robotic companions to address mental health concerns and provide emotional support. 
	- We have five ongoing projects related to our lab and institute missions.
- Projects
	- First, we are working with the TurtleBots to introduce visitors to the idea of the human fusions institute from the minute they arrive. We are researching how visitors respond to swarm robot greeters that can take them to a meeting room. We are interested in understanding how they should move, sound, and behave and how those changes with an increased number of robots.
	- Similarly, with the Baxter Robot, we are also looking at first impressions. By changing the greeting gesture, formality of verbal interaction, and physical distance between the robot and the user, we are interested to see how we can create more positive first impressions.
	- But the Baxter Robot originally had two pincers for hands, and other robotic hands are large, loud, and scary. So, in another project, we are creating a new compliant gripper that will have distributed tactile sensing throughout the hand. This will allow us to perform social touch gestures, like rubbing someone’s arm, patting their back, or shaking their hand comfortably.
	- Soon, we will start working on a new project where we will have the Baxter Robot learn from human demonstrations of naturally comforting another person so it can provide support when requesting it from a person is difficult or impossible.
	- Another project we have made a lot of progress on is how to provide emotional support or therapy when you don’t have immediate access to a mental health professional. We are using biosignals and speech to text to estimate a person’s emotion. Then we are using a fine-tuned large language model and text to speech to provide empathetic emotional support which can be provided with the Nao Robot, a VR avatar, or a chatbot (all of which we’ve developed).
	- Our last project is working to help bring humans closer together. Particularly for individuals with autism spectrum disorder and post-traumatic stress disorder, we are interested in ways that we can help these populations receive social touch and emotional support from the people around them. We are also using biosignals in this project to estimate emotional state, but we are developing a wearable to indicate the desired interaction of the wearer through things like lights, colors, social battery displays, activated fur patches and more! We hope to promote social-physical human-human interaction and improve the wearer’s emotional state.